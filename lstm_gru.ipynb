{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D\n",
    "import pandas as pd\n",
    "from preprocessing import load_and_preprocess_data\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_docs, artists_onehot_encoded, vocab_size, max_length = load_and_preprocess_data(\"spotify_millsongdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, artists_onehot_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(950,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lstm = keras.layers.LSTM(units=artists_onehot_encoded.shape[1])\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(input_dim=vocab_size, output_dim = 128, input_length = padded_docs[0].shape[0]))\n",
    "model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(256, dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(artists_onehot_encoded.shape[1], activation = 'softmax'))\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "62/62 [==============================] - 80678s 1321s/step - loss: 6.2104 - accuracy: 0.0036 - val_loss: 6.1794 - val_accuracy: 0.0026\n",
      "Epoch 2/8\n"
     ]
    }
   ],
   "source": [
    "history = model_lstm.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split = 0.1,\n",
    "    epochs = 8,\n",
    "    batch_size = 512\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(path, in_colab=False):\n",
    "    \"\"\"\n",
    "    Load the data and preprocess it, expect runtime of 20 seconds.\n",
    "    :param path: path to the data\n",
    "    :return: preprocessed data in the form of a pandas dataframe. The first item returned is the data,\n",
    "    the second is the labels, the third is the vocabulary size, and the fourth is the maximum length of a sequence\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "      \n",
    "    # remove artist with fewer than 30 songs\n",
    "    df = df.groupby('artist').filter(lambda x: len(x) > 30)\n",
    "\n",
    "    df['text'] = df['text'].apply(preprocess)\n",
    "\n",
    "    # Identify the rows that contain duplicated text in the 'song' column\n",
    "    no_covers = ~df['song'].duplicated()\n",
    "\n",
    "    # Filter the DataFrame to include only the rows with unique text\n",
    "    df = df[no_covers]\n",
    "\n",
    "    # prepare text data for a recurrent network\n",
    "    return encode_text_and_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spotify_millsongdata.csv\")\n",
    "    \n",
    "# remove artist with fewer than 30 songs\n",
    "df = df.groupby('artist').filter(lambda x: len(x) > 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Donna Summer            191\n",
       "Gordon Lightfoot        189\n",
       "Bob Dylan               188\n",
       "George Strait           188\n",
       "Cher                    187\n",
       "                       ... \n",
       "Gloria Estefan          102\n",
       "Wishbone Ash            102\n",
       "Alan Parsons Project    102\n",
       "Jason Mraz              101\n",
       "Regine Velasquez        101\n",
       "Name: artist, Length: 268, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "group_project_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6e4305676b138d1b7f009a5810f93093a69501b82ebd2fa06fb8bc39f340d64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
